{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2a030e3",
      "metadata": {
        "id": "e2a030e3"
      },
      "source": [
        "# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099562db",
      "metadata": {
        "id": "099562db"
      },
      "source": [
        "## Objectives:\n",
        "- Understand and implement advanced machine learning tasks using Spark MLlib.\n",
        "- Build and evaluate models using real-world datasets.\n",
        "- Explore techniques like feature engineering and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77df771a",
      "metadata": {
        "id": "77df771a"
      },
      "source": [
        "## Introduction to Spark MLlib\n",
        "Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ae225b",
        "outputId": "28f56763-c25f-4976-ddfb-b37429bb3577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b266267",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b266267",
        "outputId": "a5c2f3af-9027-4aff-83f2-7e865fcfaa17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ],
      "source": [
        "# Practice: Logistic Regression\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, Vectors.dense([2.0, 3.0]), 0),(2, Vectors.dense([1.0, 5.0]), 1),(3, Vectors.dense([2.5, 4.5]), 1),(4, Vectors.dense([3.0, 6.0]), 0)]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n",
        "model = lr.fit(df)\n",
        "\n",
        "# Display coefficients and summary\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9066e04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9066e04",
        "outputId": "d542b7f8-6f3b-4f4b-c7df-7d0481830230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([2.75, 5.25]), array([1.5, 4. ])]\n"
          ]
        }
      ],
      "source": [
        "# Example dataset with Vectors\n",
        "data = [(1, Vectors.dense([2.0, 3.0]), 0),(2, Vectors.dense([1.0, 5.0]), 1),(3, Vectors.dense([2.5, 4.5]), 1),(4, Vectors.dense([3.0, 6.0]), 0)]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='Features', k=2)\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n",
        "- Build a classification model using Spark MLlib and evaluate its performance.\n",
        "- Explore hyperparameter tuning using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Liberary yang diperlukan\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, year, month\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
      ],
      "metadata": {
        "id": "ca8Fi5Ct_M1H"
      },
      "id": "ca8Fi5Ct_M1H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Inisialisasi Spark Session\n",
        "spark = SparkSession.builder.appName(\"MLlib_Classification\").getOrCreate()\n",
        "\n",
        "# 2. Memuat dataset CSV\n",
        "df = spark.read.csv(\"stock_details_5_years.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Memeriksa kolom-kolom dalam dataset\n",
        "print(df.columns)\n",
        "\n",
        "# Tampilkan beberapa baris pertama untuk memverifikasi data\n",
        "df.show(5)\n",
        "\n",
        "# 3. Preprocessing data\n",
        "df = df.dropna()\n",
        "df = df.withColumn(\"label\", when(col(\"Close\") > 150, 1).otherwise(0))\n",
        "df = df.withColumn(\"year\", year(col(\"Date\"))).withColumn(\"month\", month(col(\"Date\")))\n",
        "\n",
        "# 4. Mengonversi 'Company' menjadi numerik menggunakan StringIndexer dan OneHotEncoder\n",
        "indexer = StringIndexer(inputCol=\"Company\", outputCol=\"companyIndex\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "encoder = OneHotEncoder(inputCol=\"companyIndex\", outputCol=\"companyVec\")\n",
        "df = encoder.fit(df).transform(df)\n",
        "\n",
        "# 5. Menggabungkan fitur menjadi satu vektor\n",
        "feature_columns = [col for col in df.columns if col not in [\"Date\", \"Company\", \"label\", \"companyIndex\", \"Close\"]]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(df).select(\"features\", \"label\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftR6uz0x72_T",
        "outputId": "926f5d46-caca-49db-c138-a6649736cbff"
      },
      "id": "ftR6uz0x72_T",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Company']\n",
            "+-------------------+----------------+----------------+----------------+----------------+---------+---------+------------+-------+\n",
            "|               Date|            Open|            High|             Low|           Close|   Volume|Dividends|Stock Splits|Company|\n",
            "+-------------------+----------------+----------------+----------------+----------------+---------+---------+------------+-------+\n",
            "|2018-11-29 05:00:00| 43.829760572993|43.8633538041636|42.6395935832266|43.0835075378418|167080000|      0.0|         0.0|   AAPL|\n",
            "|2018-11-29 05:00:00|104.769074332185|105.519257086357|103.534594914971|104.636131286621| 28123200|      0.0|         0.0|   MSFT|\n",
            "|2018-11-29 05:00:00|54.1764984130859|55.0074996948242|54.0999984741211|54.7290000915527| 31004000|      0.0|         0.0|  GOOGL|\n",
            "|2018-11-29 05:00:00|83.7494964599609|84.4994964599609|82.6165008544922|83.6784973144531|132264000|      0.0|         0.0|   AMZN|\n",
            "|2018-11-29 05:00:00|39.6927840259795|40.0649038762231|38.7351954599368|39.0378532409668| 54917200|     0.04|         0.0|   NVDA|\n",
            "+-------------------+----------------+----------------+----------------+----------------+---------+---------+------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi dataset menjadi data latih dan data uji\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Membangun model klasifikasi\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "# Melakukan prediksi pada data uji\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Mengevaluasi performa model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Akurasi Model: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St7rmlak-o3x",
        "outputId": "8da69e4f-06c4-4329-b67a-d5056d38db52"
      },
      "id": "St7rmlak-o3x",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Model: 0.9967538920172242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan grid parameter untuk tuning\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\n",
        "# Membuat cross-validator\n",
        "crossval = CrossValidator(\n",
        "    estimator=lr,\n",
        "    estimatorParamMaps=param_grid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=3\n",
        ")\n",
        "\n",
        "# Melatih model dengan cross-validation\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Mengevaluasi model yang dihasilkan\n",
        "cv_predictions = cv_model.transform(test_data)\n",
        "cv_accuracy = evaluator.evaluate(cv_predictions)\n",
        "print(f\"Akurasi Model Setelah Cross-Validation: {cv_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYJznG5G-4AR",
        "outputId": "44e1a12e-c127-48a5-e87e-8a53f1351108"
      },
      "id": "QYJznG5G-4AR",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Model Setelah Cross-Validation: 0.9744783040741968\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}